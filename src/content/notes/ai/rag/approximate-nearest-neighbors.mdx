---
title: "Approximate Nearest Neighbors (ANN)"
---

## Introduction

A traditional relational database can be used to power a RAG system but are unlikely to scale well for projects that require searching across a large number of document vectors. 
This is because traditional databases typically rely on an **exhaustive search** process which brings about significant computational overhead 
to calculate the distance between a query vector and every single document vector in the database. 

Dedicated vector databases approach this problem by employing **specialized indexing algorithms** that organize vectors in a way that enables fast **approximate searches**. 
While approximate search techniques may worsen retrieval accuracy, the **improved search latency** is generally worth it when working with large document collections in production. 

## Navigable Small World (NSW)

Navigable Small World (NSW) is an Approximate Nearest Neighbors (ANN) algorithm that leverages a **proximity graph** to search for a candidate vector that is closest to the query vector. 

### Proximity Graph

>A proximity graph is a data structure that contains nodes and edges. 
Each document vector should be mapped to a node in the graph, and edges should be added between nodes to connect the closest ones together. 

![Proximity Graph](/images/D7J467UKfw.png)

### NSW Search Algorithm

How it works is that a **random candidate node** is selected as the **starting point**, and the algorithm **recursively traverses the closest neighboring node** in the graph. 
With each traversal, the new node becomes the new candidate, and the process repeats itself until none of the neighbors are closer to the query vector than the current candidate. 

>Note that at the final step, we can also choose to return the top-k nearest neighbors to the query vector to retrieve multiple documents.

![NSW Search Algorithm](/images/dzQ16XLjoB.png)

## Hierarchical Navigable Small World (HNSW)

The search process can be further improved through the use of a **hierarchical proximity graph**. 

### Hierarchical Proximity Graph

>A hierarchical proximity graph is a proximity graph that contains multiple layers that each contain a different number of nodes. 
These layers are generated by randomly dropping out nodes from the previous layer.

The traversal process is generally quicker if we start by traversing higher layers that contain the fewest nodes, and then descending to lower layers that have more nodes. 
The process is more efficient since **initially** at the highest layers, the algorithm makes **big jumps** to get into the approximate neighborhood of the query vector. 

![Hierarchical Proximity Graph](/images/oWhIbeQt9Y.png)

While it may be computational expensive to build a good proximity graph, it is generally not a problem since the calculations required **can be separately precomputed**. 
The algorithm allows vector search to be **scalable** across billions of vectors. 

![Benefits of HNSW](/images/YppAsgXsdL.png)